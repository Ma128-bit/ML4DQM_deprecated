{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8f0958-42a3-47c6-aca0-0bec681ec1be",
   "metadata": {},
   "source": [
    "# Preparing Data 4 the AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce27c64-43a9-4acc-b502-cba9b078d1d1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dab262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import pyarrow as pa\n",
    "\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413120b2",
   "metadata": {},
   "source": [
    "### OMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1be37-a233-4292-9427-518f6e2c76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append path of oms api github repo\n",
    "sys.path.append(os.path.abspath('./oms-api-client'))\n",
    "from omsapi import OMSAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d6486",
   "metadata": {},
   "source": [
    "### Run-registry: update directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2fad6-480a-4f50-a4da-9d47751a9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install runregistry\n",
    "#IMPORTANT: change this path based on the output of\n",
    "#!pip show runregistry\n",
    "try:\n",
    "    import runregistry\n",
    "except:\n",
    "    sys.path.append('/eos/home-i03/m/mcrucian/.local/lib/python3.9/site-packages')\n",
    "    import runregistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7e271-7d37-42dd-bbb0-6c540a1fd741",
   "metadata": {},
   "source": [
    "## Directory with Monitoring Elements (ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5255c68-9716-45b1-a5fd-ec96f3108d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/eos/cms/store/group/ml/AD4MVDHackathon/ML4DQM_MUON/MEs\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# Display the available MEs in the dir\n",
    "print(\"Available MEs in dir:\")\n",
    "print('\\n'.join(sorted({match for dir_name in os.listdir(path) for match in re.findall(r'hRHGlobal[mp]\\d+', dir_name)})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd161135",
   "metadata": {},
   "source": [
    "## Choose ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_label = \"151024\" #used as a date to distinguish different versions\n",
    "me = \"hRHGlobalp4\"\n",
    "\n",
    "\n",
    "dirs = os.listdir(path)\n",
    "me_dirs = [os.path.join(path, i) for i in dirs if me in i and os.path.isdir(os.path.join(path, i))]\n",
    "#Filtered files are all the files with relevant ME\n",
    "files_all = []\n",
    "for dir in me_dirs:\n",
    "    files = os.listdir(dir)\n",
    "    me_files = [dir+\"/\"+i for i in files if me in i]\n",
    "    files_all = files_all + me_files\n",
    "filtered_files = [file for file in files_all if os.path.exists(file) and os.path.getsize(file) >= 601]\n",
    "#The directories printed below should show the eras we are using (e.g. D,E,F,G)\n",
    "print('\\n'.join(me_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021a37a",
   "metadata": {},
   "source": [
    "## Load dataframe with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439b046-fa57-4012-81f8-9f8433a30899",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monitoring_elements = dd.read_parquet(filtered_files)\n",
    "\n",
    "#Take StreamExpress dataset\n",
    "monitoring_elements = monitoring_elements[monitoring_elements['dataset'].str.contains(\"StreamExpress\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6556cee-c2b4-4dd1-844c-e12788300865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monitoring_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9bf94-1e75-40a3-b4a0-0af586ca55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = monitoring_elements[\"dataset\"].unique().compute()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f76e8",
   "metadata": {},
   "source": [
    "### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575f83a-673d-4f7f-9c22-423dfd6d1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = np.sort(np.unique(monitoring_elements[\"run_number\"].unique()))\n",
    "print(f\"Runs from {run_list[0]} to {run_list[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c760087f",
   "metadata": {},
   "source": [
    "# (Skip to a few lines below if already done previously)\n",
    "## Use run-registry API to download information about the runs and OMS to get luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95459b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runreg_df = pd.DataFrame(columns=[\"run_number\", \"class\", \"cscGOOD\", \"cscSTANDBY\", \"cscBAD\", \"cscEMPTY\", \"BAD\"])\n",
    "runreg_df = runreg_df.astype({\n",
    "    \"run_number\": 'int', \n",
    "    \"class\": 'str', \n",
    "    \"cscGOOD\": 'int', \n",
    "    \"cscSTANDBY\": 'int', \n",
    "    \"cscBAD\": 'int', \n",
    "    \"cscEMPTY\": 'int', \n",
    "    \"BAD\": 'bool'\n",
    "})\n",
    "\n",
    "total_runs = len(run_list)\n",
    "percent_increment = total_runs // 10  # Calculate the increment for each 10%\n",
    "\n",
    "for i, r in enumerate(run_list):\n",
    "    run = runregistry.get_run(run_number=int(r))\n",
    "    try:\n",
    "        dict = {\"run_number\": int(r), \"class\": run[\"class\"], \"cscGOOD\": 0, \"cscSTANDBY\":0, \"cscBAD\":0, \"cscEMPTY\":0, \"BAD\": False}\n",
    "        if 'csc-csc' in run[\"lumisections\"]:\n",
    "            data_dict = run[\"lumisections\"][\"csc-csc\"]\n",
    "            for key in data_dict.keys():\n",
    "                if key == \"GOOD\":\n",
    "                    dict[\"cscGOOD\"] = data_dict[\"GOOD\"]\n",
    "                if key == \"STANDBY\":\n",
    "                    dict[\"cscSTANDBY\"] = data_dict[\"STANDBY\"]\n",
    "                if key == \"BAD\":\n",
    "                    dict[\"cscBAD\"] = data_dict[\"BAD\"]\n",
    "                if key == \"EMPTY\":\n",
    "                    dict[\"cscEMPTY\"] = data_dict[\"EMPTY\"]\n",
    "            del data_dict\n",
    "    except:\n",
    "        dict = {\"run_number\": int(r), \"class\": \"BAD\", \"cscGOOD\": 0, \"cscSTANDBY\":0, \"cscBAD\":0, \"cscEMPTY\":0, \"BAD\": True}\n",
    "\n",
    "    if (\"Collisions\" not in dict[\"class\"]) or dict[\"cscSTANDBY\"]!=0 or dict[\"cscBAD\"]!=0 or dict[\"cscGOOD\"]==0:\n",
    "        dict[\"BAD\"] = True\n",
    "\n",
    "    runreg_df = pd.concat([runreg_df, pd.DataFrame([dict])], ignore_index=True)\n",
    "    \n",
    "    # Print progress every 10%\n",
    "    if i % percent_increment == 0:\n",
    "        print(f'Progress: {i / total_runs * 100}%')\n",
    "\n",
    "    del dict\n",
    "    del run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570892b7-5b0d-4048-9785-05354aa6d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as f:\n",
    "    try:\n",
    "        info = yaml.safe_load(f)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(f\"Cannot read the file: {exc}\")\n",
    "        \n",
    "omsapi = OMSAPI(\"https://cmsoms.cern.ch/agg/api\", \"v1\", cert_verify=False)\n",
    "omsapi.auth_oidc(info[\"APIClient\"][\"client_ID\"], info[\"APIClient\"][\"Client_Secret\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98943f7-c541-4a17-9ca4-b1f7927477ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lumi_dfs = []\n",
    "\n",
    "total_runs = len(run_list)\n",
    "percent_increment = total_runs // 10  # Calculate the increment for each 10%\n",
    "\n",
    "for i, r in enumerate(run_list):\n",
    "    #print(\"Run :\", r)\n",
    "    ls_query = omsapi.query(\"lumisections\")\n",
    "    ls_query.filter(\"run_number\", r)\n",
    "    ls_query.sort(\"lumisection_number\", asc=False).paginate(page=1, per_page=100000)\n",
    "    response = ls_query.data().json()[\"data\"]\n",
    "\n",
    "    df = pd.DataFrame([resp[\"attributes\"] for resp in response])\n",
    "    lumi_dfs.append(df)\n",
    "\n",
    "    # Print progress every 10%\n",
    "    if i % percent_increment == 0:\n",
    "        print(f'Progress: {i / total_runs * 100}%')\n",
    "\n",
    "lumi_df = pd.concat(lumi_dfs)\n",
    "\n",
    "lumi_df['castor_ready'] = lumi_df['castor_ready'].fillna(False)\n",
    "lumi_df['gem_ready'] = lumi_df['gem_ready'].fillna(False)\n",
    "lumi_df['zdc_ready'] = lumi_df['zdc_ready'].fillna(False)\n",
    "lumi_df['prescale_index'] = lumi_df['prescale_index'].fillna(-1)\n",
    "lumi_df['prescale_name'] = lumi_df['prescale_name'].fillna(\"\")\n",
    "\n",
    "lumi_df = lumi_df.rename(columns={'lumisection_number': 'ls_number'})\n",
    "lumi_df[\"mean_lumi\"]=(lumi_df[\"init_lumi\"]+lumi_df[\"end_lumi\"])/2\n",
    "\n",
    "dtype_dict = {'prescale_name': str, 'rp_time_ready': bool, \n",
    "              'rp_sect_56_ready': bool, 'rp_sect_45_ready': bool, \n",
    "              'start_time': str, 'end_time': str}\n",
    "lumi_df = lumi_df.astype(dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9d700",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/eos/cms/store/group/ml/AD4MVDHackathon/ML4DQM_MUON/run_info\"\n",
    "filename = \"run_info.h5\"\n",
    "\n",
    "run_list_df = pd.DataFrame(run_list, columns=['run_list'])\n",
    "\n",
    "# Save all dataframes to HDF5 file\n",
    "with pd.HDFStore(f\"{path}/{filename}\", 'w') as store:\n",
    "    store['run_list'] = run_list_df\n",
    "    store['lumi_df'] = lumi_df\n",
    "    store['runreg_df'] = runreg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78505b2",
   "metadata": {},
   "source": [
    "# (Skip to here if already downloaded)\n",
    "## Load already downloaded data for run information and luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f383e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/eos/cms/store/group/ml/AD4MVDHackathon/ML4DQM_MUON/run_info\"\n",
    "filename = \"run_info.h5\"\n",
    "\n",
    "with pd.HDFStore(f\"{path}/{filename}\", 'r') as store:\n",
    "    run_list_df = store['run_list']\n",
    "    lumi_df = store['lumi_df']\n",
    "    runreg_df = store['runreg_df']\n",
    "    \n",
    "#Assert that the runs available in the downloaded info data correspond to the ones needed for this dataset\n",
    "assert(all(run_list == list(run_list_df[\"run_list\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6403c5",
   "metadata": {},
   "source": [
    "## Use the run and luminosity information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_runs = (runreg_df[runreg_df['BAD']])['run_number'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_elements = monitoring_elements[~monitoring_elements['run_number'].isin(bad_runs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi_df_dask = dd.from_pandas(lumi_df, npartitions=1)\n",
    "#Conversion to dask dataframe is necessary for concatenation\n",
    "monitoring_elements = monitoring_elements.merge(lumi_df_dask, on=['run_number', 'ls_number'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b39ce-d891-48fd-b03d-7734f4989a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_elements = monitoring_elements[\n",
    "    (monitoring_elements[\"beams_stable\"] == True) &\n",
    "    (monitoring_elements[\"cscm_ready\"] == True) &\n",
    "    (monitoring_elements[\"cms_active\"] == True) &\n",
    "    (monitoring_elements[\"beam_present\"] == True) &\n",
    "    (monitoring_elements[\"physics_flag\"] == True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842c534-cc67-4af3-9a45-bd41618ea7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433a5ce-6af3-4b11-8165-5a87311c4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason some types in the table are not well understood and thus it is needed to manually\n",
    "#specify the type of some columns, using pyarrow types\n",
    "path = \"/eos/cms/store/group/ml/AD4MVDHackathon/ML4DQM_MUON/MEs_with_info\"\n",
    "\n",
    "schema = {\n",
    "    \"data\":pa.list_(pa.list_(pa.float64())),\n",
    "    \"recorded_lumi\": pa.float64(),\n",
    "    \"prescale_name\": pa.string(),\n",
    "    \"start_time\": pa.string(),\n",
    "    \"rp_sect_56_ready\": pa.bool_(),\n",
    "    \"rp_time_ready\": pa.bool_(),\n",
    "    \"delivered_lumi\": pa.float64(),\n",
    "    \"end_time\": pa.string(),\n",
    "    \"rp_sect_45_ready\": pa.bool_()\n",
    "}\n",
    "\n",
    "monitoring_elements.to_parquet(f'{path}/{me}_{out_label}_s0.parquet', schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab43ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
